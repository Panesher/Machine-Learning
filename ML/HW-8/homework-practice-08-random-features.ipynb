{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYp0bXOFK-hP"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 28.01.2022\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 14.02.2022\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 17.02.2022\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-08-random-features-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8vT0W_K-hR"
   },
   "source": [
    "### О задании\n",
    "\n",
    "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
    "\n",
    "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
    "\n",
    "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
    "\n",
    "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
    "\n",
    "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "Вам потребуется реализовать следующий алгоритм:\n",
    "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
    "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
    "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
    "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
    "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
    "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_sGunb7K-hS"
   },
   "source": [
    "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YyG6dBfjK-hS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 12:13:07.223357: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-14 12:13:07.223381: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train_pics.reshape(x_train_pics.shape[0], -1)\n",
    "x_test = x_test_pics.reshape(x_test_pics.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJNN55F7K-hT"
   },
   "source": [
    "__Задание 1. (5 баллов)__\n",
    "\n",
    "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n",
    "\n",
    "Ваша реализация должна поддерживать следующие опции:\n",
    "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
    "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
    "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
    "\n",
    "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jP8yepx8K-hT"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, pca=PCA(n_components=50), ss=StandardScaler(), classifier=LogisticRegression(),\n",
    "                 cnt_sigma_compute_samples=int(1e6), is_verbose=False):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        ss, StandardScaler: overparametrized StandardScaler, could be None if don't wanted to be used.\n",
    "\n",
    "        pca, PCA: overparametrized PCA, could be None if don't wanted to be used.\n",
    "        \n",
    "        classifier, object: could fit, predict and predict_proba.\n",
    "\n",
    "        cnt_sigma_compute_samples, int: count of samples needed to calculate sigma^2.\n",
    "\n",
    "        is_verbose, bool: if True logs out some progress logs.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.pca = pca\n",
    "        self.is_verbose = is_verbose\n",
    "        self.classifier = classifier\n",
    "        self.ss = ss\n",
    "        self.cnt_sigma_compute_samples = cnt_sigma_compute_samples\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "\n",
    "    def _make_random_samples(self, X):\n",
    "        samples = np.random.choice(X.shape[0], (self.cnt_sigma_compute_samples, 2))\n",
    "        samples[samples[:, 0] == samples[:, 1], 1] = (samples[samples[:, 0] == samples[:, 1], 0]\\\n",
    "            + np.random.randint(X.shape[0] - 1, size=samples[samples[:, 0] == samples[:, 1]].shape[0]) + 1) % X.shape[0]\n",
    "        return samples\n",
    "\n",
    "\n",
    "    def _compute_sigma2(self, X):\n",
    "        sigma2_as_vector = np.zeros(self.cnt_sigma_compute_samples)\n",
    "        samples = self._make_random_samples(X)\n",
    "        for k, (i, j) in enumerate(samples):\n",
    "            sigma2_as_vector[k] = ((X[i] - X[j]) ** 2).sum()\n",
    "        return np.median(sigma2_as_vector)\n",
    "\n",
    "    def _generate_w_b(self, X):\n",
    "        sigma2 = self._compute_sigma2(X)\n",
    "        assert sigma2 > 0, 'sigma^2 cant be less or equal 0'        \n",
    "        self.w = np.random.normal(0, 1 / np.sqrt(sigma2), (X.shape[1], self.n_features))\n",
    "        self.b = np.random.rand(self.n_features)* 2 * np.pi - np.pi\n",
    "        return self.w, self.b\n",
    "\n",
    "    def _apply_randomized_features(self, X):\n",
    "        assert self.w is not None and self.b is not None, 'w or b cant be None'\n",
    "        return np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "    def log(self, *args):\n",
    "        if self.is_verbose:\n",
    "            print(*args)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        if self.ss is not None:\n",
    "            self.log('Standart scaller fit_transform')\n",
    "            X = self.ss.fit_transform(X)\n",
    "        if self.pca is not None:\n",
    "            self.log('PCA fit_transform')\n",
    "            X = self.pca.fit_transform(X)\n",
    "        self.log('Generating w, b')\n",
    "        self._generate_w_b(X)\n",
    "        self.log('Applying w, b')\n",
    "        X = self._apply_randomized_features(X)\n",
    "        self.log('Fitting classifier')\n",
    "        self.classifier.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def _transform_data(self, X):\n",
    "        \"\"\"\n",
    "        Apply data pipeline\n",
    "        return transformed data\n",
    "        \"\"\"\n",
    "        if self.ss is not None:\n",
    "            self.log('Standart scaller transform')\n",
    "            X = self.ss.transform(X)\n",
    "        if self.pca is not None:\n",
    "            self.log('PCA transform')\n",
    "            X = self.pca.transform(X)\n",
    "        self.log('Applying w, b')\n",
    "        return self._apply_randomized_features(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        X = self._transform_data(X)\n",
    "        self.log('Predicting')\n",
    "        return self.classifier.predict_proba(X)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        X = self._transform_data(X)\n",
    "        self.log('Predicting')\n",
    "        return self.classifier.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFFPipeline()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_random_seed(997)\n",
    "pipeline = RFFPipeline()\n",
    "pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8552"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = pipeline.predict(x_test)\n",
    "accuracy_score(y_test, test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYqQUEi-K-hU"
   },
   "source": [
    "__Задание 2. (3 балла)__\n",
    "\n",
    "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
    "\n",
    "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost, не забудьте подобрать число деревьев и длину шага.\n",
    "\n",
    "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/panesher/.anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8725"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 mins training (local)\n",
    "set_random_seed(997)\n",
    "pipeline = RFFPipeline(classifier=LinearSVC())\n",
    "pipeline.fit(x_train, y_train)\n",
    "test_predict = pipeline.predict(x_test)\n",
    "lin_svc_ac_score = accuracy_score(y_test, test_predict)\n",
    "lin_svc_ac_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8725"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_svc_ac_score = 0.8725\n",
    "lin_svc_ac_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8537"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_random_seed(997)\n",
    "pipeline = RFFPipeline(n_features=100, classifier=SVC())\n",
    "pipeline.fit(x_train, y_train)\n",
    "test_predict = pipeline.predict(x_test)\n",
    "unlin_svc_ac_score = accuracy_score(y_test, test_predict)\n",
    "unlin_svc_ac_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.849"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_random_seed(997)\n",
    "pipeline = RFFPipeline(n_features=1000, classifier=SVC(kernel='linear'))\n",
    "pipeline.fit(x_train[:10000], y_train[:10000])\n",
    "test_predict = pipeline.predict(x_test)\n",
    "lin_ker_svc_ac_score = accuracy_score(y_test, test_predict)\n",
    "lin_ker_svc_ac_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8767"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_random_seed(997)\n",
    "pipeline = RFFPipeline(classifier=SVC(kernel='linear'))\n",
    "pipeline.fit(x_train, y_train)\n",
    "test_predict = pipeline.predict(x_test)\n",
    "lin_ker_svc_ac_score = accuracy_score(y_test, test_predict)\n",
    "lin_ker_svc_ac_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from IPython.display import clear_output\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'subsample': 0.0563847955091646, 'eta': 0.895550346641276, 'gamma': 9.984581889051787, 'max_depth': 33, 'n_estimators': 50} \n",
      "Result: 0.8885\n"
     ]
    }
   ],
   "source": [
    "def train_and_test_xgb(trial):\n",
    "    params = dict()\n",
    "    params.update({'subsample' : trial.suggest_float('subsample', 0.0001, 1)})\n",
    "    params.update({'learning_rate' : trial.suggest_float('eta', 0.0001, 1)})\n",
    "    params.update({'gamma' : trial.suggest_float('gamma', 0, 10)})\n",
    "    params.update({'max_depth' : trial.suggest_int('max_depth', 1, 50)})\n",
    "    model = xgb.XGBClassifier(params, objective='multi:softprob', n_estimators=trial.suggest_int('n_estimators', 1, 50))\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    return accuracy_score(y_test, model.predict(x_test))\n",
    "\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(train_and_test_xgb, n_trials=15)\n",
    "clear_output()\n",
    "\n",
    "boost_ac_score = study_xgb.best_value\n",
    "print('Best params:', study_xgb.best_params, '\\nResult:', study_xgb.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Как мы видим xgboost значимо лучше справляется с поставленной задачей, однако не сильно.\n",
    "2) Мы не пытались подобрать гиперпараметры под SVM. А значит он может быть и может лучше.\n",
    "3) Обучить xgboost довольно долго (с подбором гиперпараметров 35 минут), и уж точно можно пробовать применять линейный SVM, если нужно проверить коцепцию.\n",
    "\n",
    "Идея хорошая и работает воплне не плохо, достаточно быстро в линейном случае."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6umjhWuK-hV"
   },
   "source": [
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Проведите эксперименты:\n",
    "1. Помогает ли предварительное понижение размерности с помощью PCA? \n",
    "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
    "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_for_pipeline(*args, **kwargs):\n",
    "    set_random_seed(997)\n",
    "    pipeline = RFFPipeline(*args, **kwargs)\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    test_predict = pipeline.predict(x_test)\n",
    "    return accuracy_score(y_test, test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8552"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_for_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8607"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_for_pipeline(pca=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8627"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_for_pipeline(pca=PCA(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1116"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_for_pipeline(pca=None, ss=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8592"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_for_pipeline(ss=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Как мы видим стандарт скалер умеет делать достаточно умеет заменить функцию PCA и наоборот. Без обоих жить не очень хорошо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>0.8129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>0.8481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1778</td>\n",
       "      <td>0.8591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.8595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features   score\n",
       "0          10  0.5483\n",
       "1          56  0.8129\n",
       "2         316  0.8481\n",
       "3        1778  0.8591\n",
       "4       10000  0.8595"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNT_N_FEATURES = 5\n",
    "\n",
    "df = pd.DataFrame({'n_features': np.logspace(1, 4, CNT_N_FEATURES).astype(int), 'score': [0] * CNT_N_FEATURES})\n",
    "for i, n_features in enumerate(df['n_features']):\n",
    "    df.loc[i, 'score'] = accuracy_for_pipeline(n_features=n_features)\n",
    "clear_output()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Монотонно возрастающе. Как мы видим аккурси выходит на плато (что в общем очевидно ограниченностью)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.8552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC()</td>\n",
       "      <td>0.8725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             classifier   score\n",
       "0  LogisticRegression()  0.8552\n",
       "1           LinearSVC()  0.8725"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'classifier': [LogisticRegression(), LinearSVC()], 'score': [0] * 2})\n",
    "for i, classifier in enumerate(df['classifier']):\n",
    "    df.loc[i, 'score'] = accuracy_for_pipeline(classifier=classifier)\n",
    "clear_output()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Разница как мы видим есть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJqXVuasK-hW"
   },
   "source": [
    "### Бонус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVDWHCdrK-hX"
   },
   "source": [
    "__Задание 4. (Максимум 2 балла)__ Успешно скипнуто, сразу к 5 переходим\n",
    "\n",
    "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет). Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSxvGI9iK-hX"
   },
   "outputs": [],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pc7-1jmK-hY"
   },
   "source": [
    "__Задание 5. (Максимум 2 балла)__\n",
    "\n",
    "Поэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dWj-O2vjK-hY"
   },
   "outputs": [],
   "source": [
    "class FunctionRFFP(RFFPipeline):\n",
    "    def __init__(self, function=np.cos, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.function = function\n",
    "\n",
    "    def _apply_randomized_features(self, X):\n",
    "        assert self.w is not None and self.b is not None, 'w or b cant be None'\n",
    "        return self.function(X.dot(self.w) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_for_model(function, *args, **kwargs):\n",
    "    set_random_seed(997)\n",
    "    pipeline = FunctionRFFP(function, *args, **kwargs)\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    test_predict = pipeline.predict(x_test)\n",
    "    clear_output()\n",
    "    return accuracy_score(y_test, test_predict)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp: 0.1306\n"
     ]
    }
   ],
   "source": [
    "print('exp:', accuracy_for_model(np.exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sign: 0.8293\n"
     ]
    }
   ],
   "source": [
    "print('sign:', accuracy_for_model(np.sign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU: 0.8238\n"
     ]
    }
   ],
   "source": [
    "print('ReLU:', accuracy_for_model(relu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost over random PCA: 0.8507\n"
     ]
    }
   ],
   "source": [
    "print('XGBoost over random PCA:', accuracy_for_model(np.cos, n_features=100, classifier=xgb.XGBClassifier(\n",
    "                                                     objective='multi:softprob', max_depth=33, n_estimators=20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC over random PCA: 0.8278\n"
     ]
    }
   ],
   "source": [
    "print('LinearSVC over random PCA:', accuracy_for_model(np.cos, n_features=100, classifier=LinearSVC()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost показывает лучшее качетсво (если увеличить количество признаков, то скорее всего тоже).\n",
    "\n",
    "В целом оно и понятно, если у нас достаточно рандомизированные данные из понятного распределения XGBoost посильнее, чем линейная модель."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-practice-08-random-features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
